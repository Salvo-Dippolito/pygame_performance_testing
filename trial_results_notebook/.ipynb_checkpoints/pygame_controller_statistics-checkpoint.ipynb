{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c798efa",
   "metadata": {},
   "source": [
    "# Performance Benchmarking: A Comparative Analysis of My Controller and a State-of-the-Art Benchmark\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook the performance of the algorithm proposed as the solution of the first assignment of the Research Track 1 course (we'll call it controller 1) will be compared to the performance of another algorithm that was proposed as a standard solution to the same assignment (we'll call it controller 2). The performance evaluation extends to 46 trials, at every trial the arena where the robots are being tested gets modified and both controllers get tested on the same randomly generated map.\n",
    "The analysis focuses on lap times, so how fast can the robot complete a full lap around the 'sunny side up arena' map, additionally the number of missed silver tokens and failed laps will also be considered. All data has been automatically measured by scripts integrated into the controller's code.\n",
    "\n",
    "Since we're taking more than 30 samples for each variable in each run, we can expext the resulting lap times to follow a normal distribution and thus a paired t-test can be performed to compare the two algorithm's performances. Here are the null and the alternative hypotheses, respectively $H_{0}$ and $H_{a}$.\n",
    "$$\n",
    "H_{0} : \\mu_{1} = \\mu_{2}\n",
    "$$\n",
    "$$\n",
    "H_{a} : \\mu_{1} < \\mu_{2}\n",
    "$$\n",
    "\n",
    "Where $\\mu_{1}$ and $\\mu_{2}$ are the average lap times of controller 1 and controller 2 respectively, so we're posing as an alternative hypothesis that controller 1 is on average faster than controller 2 around our track. The significance level assumed for this analysis is $\\alpha=0.05$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6796b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T06:04:37.472629Z",
     "start_time": "2024-02-04T06:04:37.468739Z"
    }
   },
   "source": [
    "## Extracting data from log file\n",
    " Before we analyze our data we have to extract it from our formatted log file. We'll save lap times, number of failed object grasps and number of failed object detections in three lists and the number of failed trials in a dnf variable that we'll later explain in more detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba80e5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T20:00:06.846709Z",
     "start_time": "2024-02-04T20:00:06.834052Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'test.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15950/82491080.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'test.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mcontroller1_seconds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'assignment_1_controller'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mcontroller2_seconds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdnf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'benchmark_controller'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_15950/82491080.py\u001b[0m in \u001b[0;36mextract_data\u001b[0;34m(filename, controller)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'test.txt'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "def extract_data(filename, controller):\n",
    "    seconds_list = []\n",
    "    failed_grabs_list = []\n",
    "    missed_tokens_list = []\n",
    "    dnf=0\n",
    "    \n",
    "    \n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        \n",
    "        for i in range(len(lines)):\n",
    "            if controller in lines[i].strip().split(' '):\n",
    "                dnf_flag=1\n",
    "                while(lines[i].strip() != '---------------------------'):\n",
    "                    if 'loop' in lines[i].strip().split(' '):\n",
    "                        seconds_list.append(lines[i].strip().split(' ')[6])\n",
    "                        missed_tokens_list.append(int(lines[i].strip().split(' ')[17]))\n",
    "                        failed_grabs_list.append(int(lines[i].strip().split(' ')[13]))\n",
    "                        dnf_flag=0\n",
    "                    i +=1\n",
    "                if dnf_flag==1:\n",
    "                    dnf+=1\n",
    "                    \n",
    "    return seconds_list, missed_tokens_list, failed_grabs_list, dnf\n",
    "\n",
    "filename = 'test.txt'\n",
    "\n",
    "controller1_seconds, missed1, failed1, dnf1 = extract_data(filename, 'assignment_1_controller')\n",
    "controller2_seconds, missed2, failed2, dnf2 = extract_data(filename, 'benchmark_controller')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff7b5ad",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "Now that we have our data saved in lists and variables, we can visualize it more clearly by using functions from the seaborn, matplotlib and scipy libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6194e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T20:00:06.849142Z",
     "start_time": "2024-02-04T20:00:06.849121Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "# convert data to floats\n",
    "data1 = [float(value) for value in controller1_seconds]\n",
    "data2 = [float(value) for value in controller2_seconds]\n",
    "\n",
    "# Set a larger figure size\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# create a KDE plot with actual probability on the y-axis\n",
    "sns.kdeplot(data1, color=\"skyblue\", fill=True, label=\"Controller 1\", common_norm=False)\n",
    "sns.kdeplot(data2, color=\"moccasin\", fill=True, label=\"Controller 2\", common_norm=False)\n",
    "\n",
    "# manually adjust y-axis ticks to represent probabilities\n",
    "plt.yticks(plt.yticks()[0], [f'{tick:.2%}' for tick in plt.yticks()[0]])\n",
    "\n",
    "# overlay a normal distribution on the plot\n",
    "xmin, xmax = plt.xlim()\n",
    "\n",
    "x = np.linspace(xmin, xmax, 100)\n",
    "mu, std = np.mean(data1), np.std(data1)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, linewidth=2, label=\"Normal Distribution (Controller 1)\",color=\"blue\")\n",
    "\n",
    "mu, std = np.mean(data2), np.std(data2)\n",
    "p = norm.pdf(x, mu, std)\n",
    "plt.plot(x, p, linewidth=2, label=\"Normal Distribution (Controller 2)\",color=\"orange\")\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel(\"Lap Times [s]\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.title(\"Kernel Density Estimate Plot with Normal Distribution Overlay\")\n",
    "\n",
    "# Show the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167e9c67",
   "metadata": {},
   "source": [
    "## Data Analysis\n",
    "\n",
    "From the graph we just plotted, it's clear that, given the sample size, the probability density functions derived from our samples more or less follow their normal curves. This means that to compare the results of our two different controllers, we can perform a t-test to validate or refute our alternate hypothesis $H_{a}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c15da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T20:00:06.850714Z",
     "start_time": "2024-02-04T20:00:06.850699Z"
    }
   },
   "outputs": [],
   "source": [
    "# uncomment if the scipy package is missing:\n",
    "# !pip3 install scipy\n",
    "# remove excess elements from the longer list\n",
    "\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "\n",
    "def display_table(data):\n",
    "    html = \"<table style='width:50%'>\"  \n",
    "    for row in data:\n",
    "        html += \"<tr>\"\n",
    "        for field in row:\n",
    "            html += \"<td><h4>%s</h4></td>\" % (field)\n",
    "        html += \"</tr>\"\n",
    "    html += \"</table>\"\n",
    "    display(HTML(html))\n",
    "\n",
    "# compare the lengths of the two lists\n",
    "len1 = len(data1)\n",
    "len2 = len(data2)\n",
    "\n",
    "#to perform the test we need to get the same number of samples from our controllers' recorded lap times\n",
    "if len1 > len2:\n",
    "    data1 = random.sample(data1, len2)\n",
    "elif len2 > len1:\n",
    "    data2 = random.sample(data2, len1)\n",
    "\n",
    "\n",
    "# compare the two datasets and get T and P values\n",
    "t_value, p_value = stats.ttest_rel(data1, data2)\n",
    "\n",
    "\n",
    "data = [['T-value:', t_value], ['P-value:', p_value]]\n",
    "display_table(data)\n",
    "one_tailed_p_value = float(\"{:.18f}\".format(p_value / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4758b",
   "metadata": {
    "variables": {
     "one_tailed_p_value": "1.57e-16"
    }
   },
   "source": [
    " Since the $H_{a}$ we've set is a directional hypothesis, to check if our results are statistically significant, we can simply check if  $\\frac{pvalue}{2}<\\alpha$ in a one tailed test. Considering that we set a significance level of 5%, our result of $\\frac{pvalue}{2}$= {one_tailed_p_value} clearly satisfies the conditions to accept our alternate hypothesis. Considering then also our negative T value, we can confidently state that on average controller 1 will be expected to be faster at guiding our robot around the track than controlller 2, which is considered as a standard solution to this problem.  \n",
    " \n",
    " These results have been gathered from the times that both controllers managed to finish a lap track in under 200 seconds, since it has been decided that, for the purpose of testing, a lap time over 200 seconds means that the robot has either crashed permanently into a wall or that it has turned around and has wasted time traversing the track the wrong way around. Both of these occurrences are counted under the 'dnf' variable for both controllers, here's a representation of both controllers' dnf percentage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bd9030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T20:00:06.851492Z",
     "start_time": "2024-02-04T20:00:06.851477Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "dnf_percentage1 = dnf1/46 * 100\n",
    "labels1 = [f'Failed Trials:{dnf1}', 'Successful Trials']\n",
    "sizes1 = [dnf_percentage1, 100 - dnf_percentage1]\n",
    "\n",
    "dnf_percentage2 = dnf2/46 * 100\n",
    "labels2 = [f'Failed Trials:{dnf2}', 'Successful Trials']\n",
    "sizes2 = [dnf_percentage2, 100 - dnf_percentage2]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt1 = plt.subplot(1, 2, 1)\n",
    "plt2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "plt1.pie(sizes1, labels=labels1, autopct='%1.1f%%', startangle=140)\n",
    "plt1.axis('equal')\n",
    "plt1.set_title('Controller 1')\n",
    "\n",
    "plt2.pie(sizes2, labels=labels2, autopct='%1.1f%%', startangle=140)\n",
    "plt2.axis('equal')\n",
    "plt2.set_title('Controller 2')\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf5ffe2",
   "metadata": {},
   "source": [
    "From these charts we can see that in the trials performed controller 1 has also had a lower dnf rate than controller2.\n",
    "\n",
    "Lastly, we can visualize how effective the two controllers are at detecting and moving silver tokens out of the robot's path by summing the number of all recorded missed objects and plotting them in two other pie charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3be631",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T20:00:07.271155Z",
     "start_time": "2024-02-04T20:00:06.853736Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'len1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15950/3399880363.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mobjects_encountered1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmissed_detections1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissed1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'len1' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "objects_encountered1 = len1 * 7\n",
    "\n",
    "missed_detections1 = sum(missed1)\n",
    "missed_percentage1 = missed_detections1 / objects_encountered1 * 100\n",
    "labels1 = [f'Missed Detections:{missed_detections1}', 'Successful Detections']\n",
    "sizes1 = [missed_percentage1, 100 - missed_percentage1]\n",
    "\n",
    "objects_encountered2 = len2 * 7\n",
    "missed_detections2 = sum(missed2)\n",
    "missed_percentage2 = missed_detections2 / objects_encountered2 * 100\n",
    "labels2 = [f'Missed Detections:{missed_detections2}', 'Successful Detections']\n",
    "sizes2 = [missed_percentage2, 100 - missed_percentage2]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "plt1 = plt.subplot(1, 2, 1)\n",
    "plt2 = plt.subplot(1, 2, 2)\n",
    "\n",
    "plt1.pie(sizes1, labels=labels1, autopct='%1.1f%%', startangle=140)\n",
    "plt1.axis('equal')\n",
    "plt1.set_title('Controller 1')\n",
    "\n",
    "plt2.pie(sizes2, labels=labels2, autopct='%1.1f%%', startangle=140)\n",
    "plt2.axis('equal')\n",
    "plt2.set_title('Controller 2')\n",
    "\n",
    "# Show the pie chart\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578aa56",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "Under the testing conditions described in this repository, we can infer that controller 1 can drive the robot faster than controller 2 around a track where silver tokens are spawned randomly within the limits of the track. Controller 1 has also demonstrated a higher success rate at detecting silver tokens and has been able to succesfully complete track laps more often than controller2 over the trials performed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
